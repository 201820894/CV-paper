{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 32, 32, 3) (20, 1)\n"
     ]
    }
   ],
   "source": [
    "train_images = np.random.randint(256, size=(20,32,32,3))\n",
    "train_labels = np.random.randint(2, size=(20,1))\n",
    "print(train_images.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorData(Dataset):\n",
    "    # 외부에 있는 데이터를 가져오기 위해 외부에서 데이터가 들어올 수 있도록, x_data, y_data 변수를 지정\n",
    "    def __init__(self, x_data, y_data):\n",
    "        #들어온 x는 tensor형태로 변환\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        # tensor data의 형태는 (배치사이즈, 채널사이즈, 이미지 너비, 높이)의 형태임\n",
    "        # 따라서 들어온 데이터의 형식을 permute함수를 활용하여 바꾸어주어야함.\n",
    "        self.x_data = self.x_data.permute(0,3,1,2)  # 인덱스 번호로 바꾸어주는 것 # 이미지 개수, 채널 수, 이미지 너비, 높이\n",
    "        self.y_data = torch.LongTensor(y_data) # float tensor / long tensor 로 숫자 속성을 정해줄 수 있음\n",
    "        self.len = self.y_data.shape[0]\n",
    "\n",
    "    # x,y를 튜플형태로 바깥으로 내보내기\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인스터스(데이터) 생성\n",
    "train_data = TensorData(train_images, train_labels)\n",
    "\n",
    "# 만들어진 데이터가 배치형태로 만들어줘야하니까 DataLoader에다가 넣어줌\n",
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[189.,   4., 248.,  ..., 169.,  88., 238.],\n",
       "          [ 60., 138., 171.,  ..., 170., 129., 200.],\n",
       "          [ 26.,  64.,  47.,  ..., 207.,  20., 225.],\n",
       "          ...,\n",
       "          [167., 243., 240.,  ..., 177., 247.,  23.],\n",
       "          [161.,   4., 151.,  ..., 217.,  75.,  81.],\n",
       "          [186.,  55.,   2.,  ...,  82.,  56.,   1.]],\n",
       " \n",
       "         [[117., 218., 145.,  ...,  70.,  57., 104.],\n",
       "          [ 57.,  41., 187.,  ...,  58., 181., 204.],\n",
       "          [188.,  75., 166.,  ..., 108., 215.,  43.],\n",
       "          ...,\n",
       "          [159., 146., 145.,  ..., 203., 149.,  24.],\n",
       "          [244., 166., 177.,  ..., 251., 119., 102.],\n",
       "          [222., 214., 166.,  ..., 186., 114.,  80.]],\n",
       " \n",
       "         [[  7., 233.,  91.,  ..., 231., 154., 130.],\n",
       "          [213.,   9., 152.,  ..., 159., 247., 187.],\n",
       "          [ 44., 201.,  10.,  ...,  67., 240.,  95.],\n",
       "          ...,\n",
       "          [ 57., 167., 136.,  ..., 128., 170., 238.],\n",
       "          [ 98., 175., 241.,  ..., 165., 139., 182.],\n",
       "          [ 90., 177., 202.,  ..., 124., 198., 136.]]]),\n",
       " tensor([1]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x25da8ee2440>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f: # Read binary: PIL image는 binary로 읽어야\n",
    "        with Image.open(f) as img: # Open image\n",
    "            #(H, W, 3)\n",
    "            return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=pil_loader('0000000000.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wongyun\\AppData\\Local\\Temp\\ipykernel_18800\\1241825421.py:2: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  img_tensor=transforms.Resize((192, 640), interpolation=Image.ANTIALIAS)(img)\n",
      "c:\\Users\\wongyun\\miniconda3\\envs\\torchstudy\\lib\\site-packages\\torchvision\\transforms\\transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "img_tensor=transforms.Resize((192, 640), interpolation=Image.ANTIALIAS)(img)\n",
    "img_tensor=transforms.ToTensor()(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 192, 640])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from superglue_networks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_points(\n",
    "        input_pairs, resize_float=True, max_length=-1, \n",
    "        superglue='outdoor', max_keypoints=1024, keypoint_threshold=0.005,\n",
    "        nms_radius=4, sinkhorn_iterations=20, match_threshold=0.2, \n",
    "        resize=[640, 480], shuffle=True):\n",
    "\n",
    "    torch.set_grad_enabled(False)\n",
    "    if len(resize) == 2 and resize[1] == -1:\n",
    "        resize = resize[0:1]\n",
    "    if len(resize) == 2:\n",
    "        print('Will resize to {}x{} (WxH)'.format(\n",
    "            resize[0], resize[1]))\n",
    "    elif len(resize) == 1 and resize[0] > 0:\n",
    "        print('Will resize max dimension to {}'.format(resize[0]))\n",
    "    elif len(resize) == 1:\n",
    "        print('Will not resize images')\n",
    "    else:\n",
    "        raise ValueError('Cannot specify more than two integers for --resize')\n",
    "\n",
    "    scene0, scene1 =input_pairs\n",
    "\n",
    "    # Load the SuperPoint and SuperGlue models.\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    #print('Running inference on device \\\"{}\\\"'.format(device))\n",
    "    config = {\n",
    "        'superpoint': {\n",
    "            'nms_radius': nms_radius,\n",
    "            'keypoint_threshold': keypoint_threshold,\n",
    "            'max_keypoints': max_keypoints\n",
    "        },\n",
    "        'superglue': {\n",
    "            'weights': superglue,\n",
    "            'sinkhorn_iterations': sinkhorn_iterations,\n",
    "            'match_threshold': match_threshold,\n",
    "        }\n",
    "    }\n",
    "    matching = Matching(config).eval().to(device)\n",
    "\n",
    "    timer = AverageTimer(newline=True)\n",
    "    match_index = []\n",
    "    \n",
    "    pred = matching({'image0': input_pairs[0], 'image1': input_pairs[1]})\n",
    "    pred = {k: v[0].cpu().numpy() for k, v in pred.items()}\n",
    "    kpts0, kpts1 = pred['keypoints0'], pred['keypoints1']\n",
    "    matches, conf = pred['matches0'], pred['matching_scores0']\n",
    "    timer.update('matcher')\n",
    "    # Write the matches to disk.\n",
    "    out_matches = {'keypoints0': kpts0, 'keypoints1': kpts1,\n",
    "                   'matches': matches, 'match_confidence': conf}\n",
    "    match_index.append(out_matches)\n",
    "    #for i, pair in enumerate(pairs): 안에\n",
    "    # return here\n",
    "    return match_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 1242)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1=cv2.imread(\"0000000000.png\", 0)\n",
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "859a37aee6888f28430db123f8046c8eb89a20c3b81731796a6bb095b479e9f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
