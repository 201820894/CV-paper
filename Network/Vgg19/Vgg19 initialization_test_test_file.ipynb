{"cells":[{"cell_type":"markdown","metadata":{"id":"Cx5ZozAo6t-6"},"source":["## Define dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["69d4e5ec840246c5a2f97be609111f0d","36bc47aa2f384c3689f6440de4461180","8b810935f1b84338be54fb2723573bfb","2292bc7b32fe481286ffcf3a5f07ec12","b7a459235e444f83b14a0cb8610ae634","6a16f05ffcb146cfaf18db7d1cc9d3ec","9a267d737e2248268c7923839b5481f9","b51570cf8f28471b8c3b93f160e4abc5","643d5ae500b441cda8c38bebc8c281b8","03f32f5fc5114f77ba189a9cd680ddbe","a8a6c7d472be48079b60fb24003865aa"]},"executionInfo":{"elapsed":21412,"status":"ok","timestamp":1660880150293,"user":{"displayName":"유원균","userId":"02497608946859644371"},"user_tz":-540},"id":"Xtnn312g5VYM","outputId":"171360e3-bd49-46c7-b970-c67f9c98b136"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["from torchvision import transforms, datasets\n","from torch.utils.data import DataLoader\n","\n","batch_size=100\n","\n","transform=transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n","])\n","\n","cifar_path=\"../../Datasets/cifar10\"\n","weight_path=\"../../Weights/Vgg19\"\n","\n","train=datasets.CIFAR10(root=cifar_path, download=True, train=True, transform=transform)\n","\n","\n","test=datasets.CIFAR10(root=cifar_path, download=True, train=False, transform=transform)\n","test_dl=DataLoader(test, batch_size=batch_size)\n"," \n","class_=('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"]},{"cell_type":"markdown","metadata":{},"source":["### Train, Validation split"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["#train:40000\n","#val:10000\n"]}],"source":["import numpy as np\n","from sklearn.model_selection import StratifiedShuffleSplit\n","\n","indices=list(range(len(train)))\n","values=[y for _,y in train]\n","\n","s=StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n","for train_idx, val_idx in s.split(indices, values):\n","    print(f\"#train:{len(train_idx)}\")\n","    print(f\"#val:{len(val_idx)}\")"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["train distribution:Counter({6: 4000, 7: 4000, 8: 4000, 3: 4000, 2: 4000, 1: 4000, 4: 4000, 9: 4000, 0: 4000, 5: 4000})\n","validation distribution:Counter({2: 1000, 7: 1000, 1: 1000, 9: 1000, 6: 1000, 8: 1000, 0: 1000, 3: 1000, 5: 1000, 4: 1000})\n"]}],"source":["import collections\n","from torch.utils.data import Subset\n","\n","val=Subset(train, val_idx)\n","train=Subset(train, train_idx)\n","\n","val_count=collections.Counter([y for _, y in val])\n","train_count=collections.Counter([y for _, y in train])\n","\n","print(f\"train distribution:{train_count}\")\n","print(f\"validation distribution:{val_count}\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["train_dl=DataLoader(train, batch_size=batch_size)\n","val_dl=DataLoader(val, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{"id":"3VfCx-TN9zR3"},"source":["### Define Model"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1660880150299,"user":{"displayName":"유원균","userId":"02497608946859644371"},"user_tz":-540},"id":"ahDAg9mk7ROk"},"outputs":[],"source":["import torch.nn as nn\n","# On thesis paper, initializion is done by weights with pretrained 11 layer net\n","# But they also mentioned  it is possible to initialize the weights without pre training by using \"glorot et al 2010\"\n","\n","class VGG19(nn.Module):\n","  def __init__(self, initialization, num_classes=10):\n","    super(VGG19, self).__init__()\n","\n","    self.initialization=initialization\n","    \n","    self.conv=nn.Sequential(\n","        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(64),\n","        nn.ReLU(), #64, 32, 32\n","        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(64),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2,2), #64, 16, 16\n","\n","        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(128),\n","        nn.ReLU(), #128, 16, 16\n","        nn.Conv2d(128, 128, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(128),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2, 2), #128, 8, 8\n","\n","        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.ReLU(),\n","        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.ReLU(),\n","        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.ReLU(),\n","        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2, 2), #256, 4, 4\n","\n","        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.ReLU(),      \n","        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.ReLU(),    \n","        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.ReLU(),    \n","        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2, 2), #512, 2, 2 \n","\n","        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.ReLU(),      \n","        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.ReLU(),    \n","        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.ReLU(),    \n","        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2, 2), #512, 1, 1 \n","    )\n","    self.classifier=nn.Sequential(\n","        nn.Dropout(0.2),\n","        nn.Linear(512, 1000),\n","        nn.ReLU(),\n","        nn.Dropout(0.2),\n","        nn.Linear(1000, 500),\n","        nn.ReLU(),\n","        nn.Linear(500, num_classes)\n","    )\n","    \"\"\"\n","    for layer in self.modules(): #Use 4 normalization\n","          if isinstance(layer, (nn.Conv2d or nn.BatchNorm2d or nn.Linear)):\n","                  if initialization == \"Xavier uniform\":\n","                      nn.init.xavier_uniform_(layer.weight.data)\n","                  if initialization == \"Xavier normal\":\n","                      nn.init.xavier_normal_(layer.weight.data)\n","                  if initialization == \"He uniform\":\n","                      nn.init.kaiming_uniform_(layer.weight.data, mode='fan_in', nonlinearity='relu')\n","                  if initialization == \"He normal\":\n","                      nn.init.kaiming_normal_(layer.weight.data, mode='fan_in', nonlinearity='relu')\n","                  if initialization == \"Normal\":\n","                      nn.init.normal_(layer.weight.data, mean=0, std=0.01)  \n","    \"\"\"                 \n","  def init_name(self):\n","    return self.initialization\n","                                    \n","  def forward(self, x):\n","    output=self.conv(x)\n","    output=output.view(-1, 512)\n","    output=self.classifier(output)\n","    return output\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":799,"status":"ok","timestamp":1660880202151,"user":{"displayName":"유원균","userId":"02497608946859644371"},"user_tz":-540},"id":"L0dha5Nx9cHW","outputId":"ee1df430-7821-4a1e-f6f3-6a9d38d62026"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           1,792\n","       BatchNorm2d-2           [-1, 64, 32, 32]             128\n","              ReLU-3           [-1, 64, 32, 32]               0\n","            Conv2d-4           [-1, 64, 32, 32]          36,928\n","       BatchNorm2d-5           [-1, 64, 32, 32]             128\n","              ReLU-6           [-1, 64, 32, 32]               0\n","         MaxPool2d-7           [-1, 64, 16, 16]               0\n","            Conv2d-8          [-1, 128, 16, 16]          73,856\n","       BatchNorm2d-9          [-1, 128, 16, 16]             256\n","             ReLU-10          [-1, 128, 16, 16]               0\n","           Conv2d-11          [-1, 128, 16, 16]         147,584\n","      BatchNorm2d-12          [-1, 128, 16, 16]             256\n","             ReLU-13          [-1, 128, 16, 16]               0\n","        MaxPool2d-14            [-1, 128, 8, 8]               0\n","           Conv2d-15            [-1, 256, 8, 8]         295,168\n","      BatchNorm2d-16            [-1, 256, 8, 8]             512\n","             ReLU-17            [-1, 256, 8, 8]               0\n","           Conv2d-18            [-1, 256, 8, 8]         590,080\n","      BatchNorm2d-19            [-1, 256, 8, 8]             512\n","             ReLU-20            [-1, 256, 8, 8]               0\n","           Conv2d-21            [-1, 256, 8, 8]         590,080\n","      BatchNorm2d-22            [-1, 256, 8, 8]             512\n","             ReLU-23            [-1, 256, 8, 8]               0\n","           Conv2d-24            [-1, 256, 8, 8]         590,080\n","      BatchNorm2d-25            [-1, 256, 8, 8]             512\n","             ReLU-26            [-1, 256, 8, 8]               0\n","        MaxPool2d-27            [-1, 256, 4, 4]               0\n","           Conv2d-28            [-1, 512, 4, 4]       1,180,160\n","      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n","             ReLU-30            [-1, 512, 4, 4]               0\n","           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n","      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n","             ReLU-33            [-1, 512, 4, 4]               0\n","           Conv2d-34            [-1, 512, 4, 4]       2,359,808\n","      BatchNorm2d-35            [-1, 512, 4, 4]           1,024\n","             ReLU-36            [-1, 512, 4, 4]               0\n","           Conv2d-37            [-1, 512, 4, 4]       2,359,808\n","      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n","             ReLU-39            [-1, 512, 4, 4]               0\n","        MaxPool2d-40            [-1, 512, 2, 2]               0\n","           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n","      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n","             ReLU-43            [-1, 512, 2, 2]               0\n","           Conv2d-44            [-1, 512, 2, 2]       2,359,808\n","      BatchNorm2d-45            [-1, 512, 2, 2]           1,024\n","             ReLU-46            [-1, 512, 2, 2]               0\n","           Conv2d-47            [-1, 512, 2, 2]       2,359,808\n","      BatchNorm2d-48            [-1, 512, 2, 2]           1,024\n","             ReLU-49            [-1, 512, 2, 2]               0\n","           Conv2d-50            [-1, 512, 2, 2]       2,359,808\n","      BatchNorm2d-51            [-1, 512, 2, 2]           1,024\n","             ReLU-52            [-1, 512, 2, 2]               0\n","        MaxPool2d-53            [-1, 512, 1, 1]               0\n","          Dropout-54                  [-1, 512]               0\n","           Linear-55                 [-1, 1000]         513,000\n","             ReLU-56                 [-1, 1000]               0\n","          Dropout-57                 [-1, 1000]               0\n","           Linear-58                  [-1, 500]         500,500\n","             ReLU-59                  [-1, 500]               0\n","           Linear-60                   [-1, 10]           5,010\n","================================================================\n","Total params: 21,053,902\n","Trainable params: 21,053,902\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 7.21\n","Params size (MB): 80.31\n","Estimated Total Size (MB): 87.54\n","----------------------------------------------------------------\n","None\n"]}],"source":["import torch\n","from torchsummary import summary\n","\n","device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","\n","model_xavier_uniform=VGG19(\"Xavier uniform\").to(device)\n","model_xavier_normal=VGG19(\"Xavier normal\").to(device)\n","model_he_uniform=VGG19(\"He uniform\").to(device)\n","model_he_normal=VGG19(\"He normal\").to(device)\n","model_normal=VGG19(\"Normal\").to(device)\n","\n","models=[model_xavier_uniform, model_xavier_normal, model_he_uniform, model_he_normal, model_normal]\n","\n","print(summary(model_he_normal, input_size=(3,32, 32)))"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["model_best_acc=VGG19(\"He normal\").to(device) \n","model_state_dict=torch.load(\"..\\..\\Weights\\Vgg19\\He normal_27_0.0_vgg_acc.pt\", map_location=device)\n","model_best_acc.load_state_dict(model_state_dict)\n","\n","model_best_loss=VGG19(\"He normal\").to(device)\n","model_state_dict=torch.load(\"..\\..\\Weights\\Vgg19\\He normal_27_0.0_vgg_loss.pt\", map_location=device)\n","model_best_loss.load_state_dict(model_state_dict)"]},{"cell_type":"markdown","metadata":{},"source":["### Best Accuracy test"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["test loss: 0.7995142750065736, test accuracy: 83.0%\n"]}],"source":["running_loss=0\n","running_acc=0\n","loss_fn=nn.CrossEntropyLoss()\n","\n","model_best_loss.eval()\n","with torch.no_grad():\n","    for i, data in enumerate(test_dl): \n","        test_x, test_y= data\n","        test_x, test_y= test_x.to(device), test_y.to(device)\n","        \n","        test_pred=model_best_loss(test_x)\n","        loss=loss_fn(test_pred, test_y)\n","        _, predicted = torch.max(test_pred, 1)\n","        acc = (predicted == test_y).squeeze().int()\n","        acc = torch.sum(acc)\n","        \n","        running_loss+=loss.item()\n","        running_acc+=acc\n","        \n","    print(f\"test loss: {running_loss/i}, test accuracy: {running_acc/len(test)*100}%\")"]},{"cell_type":"markdown","metadata":{},"source":["### Best Loss test"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["test loss: 0.8031363710008487, test accuracy: 82.5%\n"]}],"source":["running_loss=0\n","running_acc=0\n","\n","model_best_acc.eval()\n","with torch.no_grad():\n","    for i, data in enumerate(test_dl): \n","        test_x, test_y= data\n","        test_x, test_y= test_x.to(device), test_y.to(device)\n","        \n","        test_pred=model_best_acc(test_x)\n","        loss=loss_fn(test_pred, test_y)\n","        _, predicted = torch.max(test_pred, 1)\n","        acc = (predicted == test_y).squeeze().int()\n","        acc = torch.sum(acc)\n","        \n","        running_loss+=loss.item()\n","        running_acc+=acc\n","        \n","    print(f\"test loss: {running_loss/i}, test accuracy: {running_acc/len(test)*100}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNETFHyGbhL8fCRAPB9MDud","collapsed_sections":[],"name":"Untitled8.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.4 ('torchstudy')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"d2a29e84b0c43c20c166437993d835aa1a00044783bb297f1abc4254f32cfca7"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"03f32f5fc5114f77ba189a9cd680ddbe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2292bc7b32fe481286ffcf3a5f07ec12":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03f32f5fc5114f77ba189a9cd680ddbe","placeholder":"​","style":"IPY_MODEL_a8a6c7d472be48079b60fb24003865aa","value":" 170498071/170498071 [00:13&lt;00:00, 13921006.72it/s]"}},"36bc47aa2f384c3689f6440de4461180":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a16f05ffcb146cfaf18db7d1cc9d3ec","placeholder":"​","style":"IPY_MODEL_9a267d737e2248268c7923839b5481f9","value":"100%"}},"643d5ae500b441cda8c38bebc8c281b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"69d4e5ec840246c5a2f97be609111f0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_36bc47aa2f384c3689f6440de4461180","IPY_MODEL_8b810935f1b84338be54fb2723573bfb","IPY_MODEL_2292bc7b32fe481286ffcf3a5f07ec12"],"layout":"IPY_MODEL_b7a459235e444f83b14a0cb8610ae634"}},"6a16f05ffcb146cfaf18db7d1cc9d3ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b810935f1b84338be54fb2723573bfb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b51570cf8f28471b8c3b93f160e4abc5","max":170498071,"min":0,"orientation":"horizontal","style":"IPY_MODEL_643d5ae500b441cda8c38bebc8c281b8","value":170498071}},"9a267d737e2248268c7923839b5481f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8a6c7d472be48079b60fb24003865aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b51570cf8f28471b8c3b93f160e4abc5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7a459235e444f83b14a0cb8610ae634":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
